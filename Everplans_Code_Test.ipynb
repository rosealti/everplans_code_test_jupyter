{
  "cells": [
    {
      "metadata": {
        "dc": {
          "key": "4"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "DvWJ44BCNS_5"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "<p>In this notebook, I parsed the dataset, cleaned up partial data, and generated two synthesized datasets which were exported as two csv files: unique_id_records_dataset.csv and aggregate_by_month_dataset.csv.</p>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bKZPjYQSo6FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "dc": {
          "key": "11"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "lTa4_hRGNS_-"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Reading From The Raw CSV File\n",
        "<p>Initially, I parsed raw event log.csv to create a dataset that has 1 record for each unique user ID, with the following columns: date of activation, total logins, total vault events, and time to activate. As time to activate is calculated with the creation date and date of activation, I created an extra column to store the creation date data.</p>\n"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "11"
        },
        "tags": [
          "sample_code"
        ],
        "collapsed": true,
        "id": "uNrCJBM3NS_-"
      },
      "cell_type": "code",
      "source": [
        "def convert_string_to_datetime(date_str: str):\n",
        "    datetime_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
        "    return datetime_object\n",
        "\n",
        "\n",
        "def parse_unique_id_data(file_path: str):\n",
        "    table_rows = {}\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "        for row in csv_reader:\n",
        "            if row[2] == 'create':\n",
        "                table_rows[row[0]] = [None, 0, 0, None, convert_string_to_datetime(row[1])]\n",
        "            if row[2] == 'activate':\n",
        "                if row[0] in table_rows:\n",
        "                    table_rows[row[0]][0] = convert_string_to_datetime(row[1])\n",
        "                    table_rows[row[0]][3] = table_rows[row[0]][0] - table_rows[row[0]][4]\n",
        "            if row[2] == 'login':\n",
        "                table_rows[row[0]][1] += 1\n",
        "            if row[2] == 'add_to_vault':\n",
        "                table_rows[row[0]][2] += 1\n",
        "    return table_rows\n",
        "\n",
        "parsed_rows = parse_unique_id_data(\"raw_event_log.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "dc": {
          "key": "18"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "GMe-PId0NS__"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Removing Extra Column From Unique Id Data\n",
        "<p>I removed the extra creation date column from the unique id dataset.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "18"
        },
        "tags": [
          "sample_code"
        ],
        "collapsed": true,
        "id": "JCV5jKj0NS__"
      },
      "cell_type": "code",
      "source": [
        "def remove_creation_date_from_unique_id_data(table_rows: dict):\n",
        "    for key in table_rows:\n",
        "        table_rows[key] = table_rows[key][:-1]\n",
        "    return table_rows\n",
        "\n",
        "all_rows = remove_creation_date_from_unique_id_data(parsed_rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Prep The Unique Id Data\n",
        "<p>I prepared the data by reformatting the date for the date of activation and the time in seconds for the time to activate.</p>"
      ],
      "metadata": {
        "id": "rkW-ewhG-CA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_unique_id_data_row(row_list: list):\n",
        "    if row_list[0] is not None:\n",
        "        row_list[0] = row_list[0].strftime('%Y-%m-%d %H:%M:%S')\n",
        "    if row_list[3] is not None:\n",
        "        row_list[3] = int(row_list[3].total_seconds())\n",
        "    return row_list\n"
      ],
      "metadata": {
        "id": "8-FruJ8S-EX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "dc": {
          "key": "25"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "FLSw22HXNTAA"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Write The Unique Id Data To A CSV File\n",
        "<p>I wrote the unique id data to the dataset_unique_id_records.csv file.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "25"
        },
        "tags": [
          "sample_code"
        ],
        "collapsed": true,
        "id": "PLqaxywINTAA"
      },
      "cell_type": "code",
      "source": [
        "def write_unique_id_data_to_file(table_header: tuple, table_rows: dict, file_path: str):\n",
        "    with open(file_path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(table_header)\n",
        "        for tbl_row in table_rows:\n",
        "            cleaned_row = prep_unique_id_data_row(table_rows[tbl_row])\n",
        "            writer.writerow((tbl_row,\n",
        "                             cleaned_row[0],\n",
        "                             cleaned_row[1],\n",
        "                             cleaned_row[2],\n",
        "                             cleaned_row[3]))\n",
        "\n",
        "all_headers = \"user\", \"date_of_activation\", \"total_logins\", \"total_vault_events\", \\\n",
        "              \"time_to_activate\"\n",
        "write_unique_id_data_to_file(all_headers, all_rows, 'dataset_unique_id_records.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Create A DataFrame For The Aggregate By Month Data\n",
        "<p>I created a dataframe using the all_headers and all_rows data from the unique id dataset.</p>"
      ],
      "metadata": {
        "id": "2j9u39Xm-sCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_unique_id_data = pd.DataFrame.from_dict(all_rows, orient='index', columns=all_headers[1:]).astype(\n",
        "        {'date_of_activation': 'datetime64'})"
      ],
      "metadata": {
        "id": "lAzKd2Wj-lbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "dc": {
          "key": "32"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "C0LJYxgDNTAB"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Prep The Aggregate By Month Data\n",
        "<p>I prepped the aggregate by month data by changing seconds to date, removing unnecessary columns, grouping the data by month and year, and renaming the appropriate columns.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "32"
        },
        "tags": [
          "sample_code"
        ],
        "collapsed": true,
        "id": "iDy0nm8oNTAB"
      },
      "cell_type": "code",
      "source": [
        "def convert_seconds_to_days(seconds_col: pd.DataFrame):\n",
        "    seconds_col = pd.to_timedelta(seconds_col, unit=\"s\")\n",
        "    day_duration = pd.to_timedelta(1, unit='D')\n",
        "    days = seconds_col / day_duration\n",
        "    return days\n",
        "\n",
        "\n",
        "def prep_aggregate_by_month_data(dataframe: pd.DataFrame):\n",
        "    dataframe.reset_index(drop=True, inplace=True)\n",
        "    dataframe = dataframe[[\"date_of_activation\", \"time_to_activate\", \"total_logins\"]].copy()\n",
        "    dataframe['time_to_activate'] = convert_seconds_to_days(dataframe['time_to_activate'])\n",
        "    dataframe.index = dataframe[\"date_of_activation\"]\n",
        "    dataframe = dataframe.groupby(dataframe[\"date_of_activation\"].dt.to_period(\"M\")).mean()\n",
        "    dataframe = dataframe.rename_axis(\"activation_month\").rename(\n",
        "        columns={\"time_to_activate\": \"average_days_to_activate\",\n",
        "                 \"total_logins\": \"average_logins\"})\n",
        "    return dataframe\n",
        "\n",
        "df_aggregate_by_month_data = prep_aggregate_by_month_data(df_unique_id_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "dc": {
          "key": "39"
        },
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "Bad0OM3UNTAC"
      },
      "cell_type": "markdown",
      "source": [
        "## 8. Write The Aggregate By Month Data to a CSV File\n",
        "<p>I wrote the aggregate by month data to the dataset_aggregate_by_month.csv file.</p>"
      ]
    },
    {
      "metadata": {
        "dc": {
          "key": "39"
        },
        "tags": [
          "sample_code"
        ],
        "collapsed": true,
        "id": "oaXJ_yjQNTAC"
      },
      "cell_type": "code",
      "source": [
        "df_aggregate_by_month_data.to_csv('dataset_aggregate_by_month.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Everplans Code Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}